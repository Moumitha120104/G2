

Our approach has 3 major parts:


User Feature Set Extraction:
Load Survey Responses Data:
Read the survey responses data from the CSV file (survey_responses.csv).
Convert the string representation of dictionary-like objects in the comment_answers column to actual dictionaries.
Extract 'Love' and 'Hate' Values:
Define a function (extract_values) to extract 'love' and 'hate' values from the survey response dictionaries.
Apply this function to create separate DataFrames (love_df and hate_df) for 'love' and 'hate' values respectively.
Preprocess 'Love' and 'Hate' Data:
Drop rows with null values from both love_df and hate_df.
Drop the negative reviews from love and the positive reviews from hate.
Convert all text data to lowercase for uniformity.
Tokenize and filter the text data to remove stopwords, non-alphabetic characters, and short words.
Lemmatize the words to their base forms, specifically focusing on nouns (NN parts of speech).
Filter out records with single-word entries to ensure meaningful analysis.
Create Dictionary and Document-Term Matrix:
Create a dictionary (dictionary_love and dictionary_hate) to map words to numeric IDs.
Generate a document-term matrix (doc_term_matrix_love and doc_term_matrix_hate) representing word frequencies for 'love' and 'hate' data using the created dictionaries.
Train LDA Models:
Use the document-term matrices to train LDA (Latent Dirichlet Allocation) models (ldamodel_love and ldamodel_hate) for topic modeling.
Generate love_topic dictionary and hate_topic dictionary for each unique user and store it in a list. Later convert this list into a dataframe.
Print and visualize the learned topics from the LDA models (topics_love and topics_hate).


Product Feature Set Extraction:
Feature Extraction:  The code extracts 'love' and 'hate' features from the survey responses, encapsulated within dictionaries.
Data Preprocessing: Null value rows within the 'love' and 'hate' DataFrames are dropped to ensure data integrity.
Textual data is normalised by converting all characters to lowercase.
Text Tokenization: The script tokenizes the textual data into individual words or tokens for further processing.
Stopword Removal and Filtering: Common stopwords, short words, and non-alphabetic characters are filtered out to focus on meaningful content.
Lemmatization: Words are lemmatized to reduce them to their base form, aiding in standardisation and analysis.
Noun Extraction: Only nouns are retained from the text, as they typically carry the most substantive meaning.
Document-Term Matrix Creation: A document-term matrix is constructed, which represents the frequency of terms within each document (survey response).
LDA Topic Modeling : Latent Dirichlet Allocation (LDA) models are constructed for both the 'love' and 'hate' DataFrames. LDA is a probabilistic model used to uncover topics within a collection of documents.The script prints the identified topics generated by the LDA models.
Visualisation: PyLDAvis is used to visually represent the identified topics, aiding in the interpretation of the topic models.

Recommendation System Using Customer & Product Features
The important functions used are - 
Custom Preprocessor Function: A custom preprocessor function custom_preprocessor is defined to remove punctuation and convert text to lowercase. This function will be used during vectorization.
Load Customer Data: The load_customer_data function reads customer data from a CSV file and stores it in a dictionary, where each key is a customer identifier and the corresponding value is a dictionary containing 'Love Value' and 'Hate Value'.
Calculate Cosine Similarity: The calculate_cosine_similarity function calculates the cosine similarity between customer and topic vectors using TF-IDF vectorization.
Find Most Relevant Topic: The find_most_relevant_topic function iterates through each customer's data, calculates the cosine similarity between their preferences and each topic's love and hate features, and selects the topic with the highest similarity as the most relevant topic for the customer.
Generate Description: The generate_description function generates a description for each customer based on the love features of the most suitable topic.
Calculate Score: The calculate_score function calculates a score indicating how well the customer fits with the chosen topic based on the cosine similarity between their preferences and the love features of the topic.
Write Results to CSV: Finally, the write_to_csv function writes the results (customer identifier, most relevant topic, description, and score) to a CSV file.




